{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanzlaJavaid/Algorithms/blob/master/ANN_META.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0xixtNbY4GV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvL1F8VfZXFq"
      },
      "outputs": [],
      "source": [
        "u0_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/user_a.csv\")\n",
        "u0_df[\"user\"] = 0\n",
        "u1_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/user_b.csv\")\n",
        "u1_df[\"user\"] = 1\n",
        "u2_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/user_c.csv\")\n",
        "u2_df[\"user\"] = 2\n",
        "u3_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/user_d.csv\")\n",
        "u3_df[\"user\"] = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3419vX7zZ9gq"
      },
      "outputs": [],
      "source": [
        "collective_df = pd.concat([u0_df,u1_df,u2_df,u3_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "wtdtJZFya0Gy",
        "outputId": "2e7e9e5d-00fb-40c1-dbed-b2e2ebd7c752"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a187819d-729d-4ddc-a785-3a064b0beaae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>AF3 delta std</th>\n",
              "      <th>AF3 delta m</th>\n",
              "      <th>AF3 theta std</th>\n",
              "      <th>AF3 theta m</th>\n",
              "      <th>AF3 alpha std</th>\n",
              "      <th>AF3 alpha m</th>\n",
              "      <th>AF3 beta std</th>\n",
              "      <th>AF3 beta m</th>\n",
              "      <th>F7 delta std</th>\n",
              "      <th>F7 delta m</th>\n",
              "      <th>F7 theta std</th>\n",
              "      <th>F7 theta m</th>\n",
              "      <th>F7 alpha std</th>\n",
              "      <th>F7 alpha m</th>\n",
              "      <th>F7 beta std</th>\n",
              "      <th>F7 beta m</th>\n",
              "      <th>F3 delta std</th>\n",
              "      <th>F3 delta m</th>\n",
              "      <th>F3 theta std</th>\n",
              "      <th>F3 theta m</th>\n",
              "      <th>F3 alpha std</th>\n",
              "      <th>F3 alpha m</th>\n",
              "      <th>F3 beta std</th>\n",
              "      <th>F3 beta m</th>\n",
              "      <th>FC5 delta std</th>\n",
              "      <th>FC5 delta m</th>\n",
              "      <th>FC5 theta std</th>\n",
              "      <th>FC5 theta m</th>\n",
              "      <th>FC5 alpha std</th>\n",
              "      <th>FC5 alpha m</th>\n",
              "      <th>FC5 beta std</th>\n",
              "      <th>FC5 beta m</th>\n",
              "      <th>T7 delta std</th>\n",
              "      <th>T7 delta m</th>\n",
              "      <th>T7 theta std</th>\n",
              "      <th>T7 theta m</th>\n",
              "      <th>T7 alpha std</th>\n",
              "      <th>T7 alpha m</th>\n",
              "      <th>T7 beta std</th>\n",
              "      <th>...</th>\n",
              "      <th>T8 delta m</th>\n",
              "      <th>T8 theta std</th>\n",
              "      <th>T8 theta m</th>\n",
              "      <th>T8 alpha std</th>\n",
              "      <th>T8 alpha m</th>\n",
              "      <th>T8 beta std</th>\n",
              "      <th>T8 beta m</th>\n",
              "      <th>FC6 delta std</th>\n",
              "      <th>FC6 delta m</th>\n",
              "      <th>FC6 theta std</th>\n",
              "      <th>FC6 theta m</th>\n",
              "      <th>FC6 alpha std</th>\n",
              "      <th>FC6 alpha m</th>\n",
              "      <th>FC6 beta std</th>\n",
              "      <th>FC6 beta m</th>\n",
              "      <th>F4 delta std</th>\n",
              "      <th>F4 delta m</th>\n",
              "      <th>F4 theta std</th>\n",
              "      <th>F4 theta m</th>\n",
              "      <th>F4 alpha std</th>\n",
              "      <th>F4 alpha m</th>\n",
              "      <th>F4 beta std</th>\n",
              "      <th>F4 beta m</th>\n",
              "      <th>F8 delta std</th>\n",
              "      <th>F8 delta_m</th>\n",
              "      <th>F8 theta std</th>\n",
              "      <th>F8 theta m</th>\n",
              "      <th>F8 alpha std</th>\n",
              "      <th>F8 alpha m</th>\n",
              "      <th>F8 beta std</th>\n",
              "      <th>F8 beta m</th>\n",
              "      <th>AF4 delta std</th>\n",
              "      <th>AF4 delta m</th>\n",
              "      <th>AF4 theta std</th>\n",
              "      <th>AF4 theta m</th>\n",
              "      <th>AF4 alpha std</th>\n",
              "      <th>AF4 alpha m</th>\n",
              "      <th>AF4 beta std</th>\n",
              "      <th>AF4 beta m</th>\n",
              "      <th>user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3569.164550</td>\n",
              "      <td>2063.892754</td>\n",
              "      <td>1.673726</td>\n",
              "      <td>4.444736</td>\n",
              "      <td>0.526209</td>\n",
              "      <td>3.002088</td>\n",
              "      <td>1.425022</td>\n",
              "      <td>3.302739</td>\n",
              "      <td>3563.803888</td>\n",
              "      <td>2060.239057</td>\n",
              "      <td>1.404089</td>\n",
              "      <td>2.279398</td>\n",
              "      <td>1.297401</td>\n",
              "      <td>1.960079</td>\n",
              "      <td>0.759956</td>\n",
              "      <td>2.038977</td>\n",
              "      <td>3709.009712</td>\n",
              "      <td>2180.647682</td>\n",
              "      <td>19.491141</td>\n",
              "      <td>39.847419</td>\n",
              "      <td>20.493348</td>\n",
              "      <td>41.228796</td>\n",
              "      <td>46.007372</td>\n",
              "      <td>73.493233</td>\n",
              "      <td>3567.365265</td>\n",
              "      <td>2062.483097</td>\n",
              "      <td>1.209996</td>\n",
              "      <td>1.771811</td>\n",
              "      <td>0.161793</td>\n",
              "      <td>1.818490</td>\n",
              "      <td>0.688672</td>\n",
              "      <td>1.641767</td>\n",
              "      <td>3559.219279</td>\n",
              "      <td>2057.363361</td>\n",
              "      <td>1.027551</td>\n",
              "      <td>2.502389</td>\n",
              "      <td>1.495156</td>\n",
              "      <td>2.207701</td>\n",
              "      <td>1.029114</td>\n",
              "      <td>...</td>\n",
              "      <td>2138.663493</td>\n",
              "      <td>19.310670</td>\n",
              "      <td>36.200836</td>\n",
              "      <td>15.881327</td>\n",
              "      <td>38.774853</td>\n",
              "      <td>43.601995</td>\n",
              "      <td>69.778363</td>\n",
              "      <td>3694.245877</td>\n",
              "      <td>2174.777021</td>\n",
              "      <td>18.426524</td>\n",
              "      <td>40.488393</td>\n",
              "      <td>16.410505</td>\n",
              "      <td>38.850336</td>\n",
              "      <td>45.329263</td>\n",
              "      <td>72.907800</td>\n",
              "      <td>3577.521434</td>\n",
              "      <td>2067.996962</td>\n",
              "      <td>1.232973</td>\n",
              "      <td>3.073659</td>\n",
              "      <td>0.919419</td>\n",
              "      <td>2.634124</td>\n",
              "      <td>3.348698</td>\n",
              "      <td>5.380652</td>\n",
              "      <td>3665.336755</td>\n",
              "      <td>2157.675046</td>\n",
              "      <td>15.543111</td>\n",
              "      <td>37.374199</td>\n",
              "      <td>15.907312</td>\n",
              "      <td>40.854795</td>\n",
              "      <td>45.468326</td>\n",
              "      <td>72.508750</td>\n",
              "      <td>3701.186330</td>\n",
              "      <td>2182.676835</td>\n",
              "      <td>18.192418</td>\n",
              "      <td>41.349662</td>\n",
              "      <td>16.004756</td>\n",
              "      <td>42.046467</td>\n",
              "      <td>46.280843</td>\n",
              "      <td>73.565719</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3568.423670</td>\n",
              "      <td>2063.099248</td>\n",
              "      <td>1.897790</td>\n",
              "      <td>3.728823</td>\n",
              "      <td>1.304186</td>\n",
              "      <td>1.854353</td>\n",
              "      <td>1.366575</td>\n",
              "      <td>2.546458</td>\n",
              "      <td>3563.560922</td>\n",
              "      <td>2059.969372</td>\n",
              "      <td>0.694171</td>\n",
              "      <td>1.971073</td>\n",
              "      <td>0.756398</td>\n",
              "      <td>1.637064</td>\n",
              "      <td>0.963158</td>\n",
              "      <td>2.117719</td>\n",
              "      <td>3721.781859</td>\n",
              "      <td>2177.507069</td>\n",
              "      <td>7.343344</td>\n",
              "      <td>39.152753</td>\n",
              "      <td>20.145638</td>\n",
              "      <td>32.934098</td>\n",
              "      <td>38.525474</td>\n",
              "      <td>68.196685</td>\n",
              "      <td>3566.746758</td>\n",
              "      <td>2061.497984</td>\n",
              "      <td>0.740290</td>\n",
              "      <td>1.815878</td>\n",
              "      <td>1.153479</td>\n",
              "      <td>1.583097</td>\n",
              "      <td>0.574245</td>\n",
              "      <td>1.616353</td>\n",
              "      <td>3559.526890</td>\n",
              "      <td>2057.324677</td>\n",
              "      <td>0.986897</td>\n",
              "      <td>2.406373</td>\n",
              "      <td>0.779043</td>\n",
              "      <td>2.993743</td>\n",
              "      <td>1.090381</td>\n",
              "      <td>...</td>\n",
              "      <td>2136.305537</td>\n",
              "      <td>9.666578</td>\n",
              "      <td>34.522405</td>\n",
              "      <td>17.767788</td>\n",
              "      <td>26.998472</td>\n",
              "      <td>36.178953</td>\n",
              "      <td>64.661308</td>\n",
              "      <td>3708.391961</td>\n",
              "      <td>2171.961977</td>\n",
              "      <td>10.150358</td>\n",
              "      <td>39.040007</td>\n",
              "      <td>16.553371</td>\n",
              "      <td>28.600763</td>\n",
              "      <td>38.483312</td>\n",
              "      <td>67.962618</td>\n",
              "      <td>3578.776662</td>\n",
              "      <td>2068.731565</td>\n",
              "      <td>1.218218</td>\n",
              "      <td>2.128704</td>\n",
              "      <td>0.352964</td>\n",
              "      <td>3.215416</td>\n",
              "      <td>3.412938</td>\n",
              "      <td>4.803989</td>\n",
              "      <td>3679.285737</td>\n",
              "      <td>2156.011819</td>\n",
              "      <td>9.227783</td>\n",
              "      <td>35.553815</td>\n",
              "      <td>18.089263</td>\n",
              "      <td>28.408800</td>\n",
              "      <td>36.551948</td>\n",
              "      <td>66.931186</td>\n",
              "      <td>3725.210509</td>\n",
              "      <td>2180.197439</td>\n",
              "      <td>8.820788</td>\n",
              "      <td>38.012788</td>\n",
              "      <td>19.601233</td>\n",
              "      <td>29.431054</td>\n",
              "      <td>38.559351</td>\n",
              "      <td>67.470041</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3568.157929</td>\n",
              "      <td>2062.445859</td>\n",
              "      <td>2.798014</td>\n",
              "      <td>2.574504</td>\n",
              "      <td>1.120537</td>\n",
              "      <td>1.958819</td>\n",
              "      <td>0.982433</td>\n",
              "      <td>2.258622</td>\n",
              "      <td>3563.279981</td>\n",
              "      <td>2059.543651</td>\n",
              "      <td>0.493677</td>\n",
              "      <td>1.222808</td>\n",
              "      <td>0.955544</td>\n",
              "      <td>2.642443</td>\n",
              "      <td>0.725119</td>\n",
              "      <td>1.846020</td>\n",
              "      <td>3723.289253</td>\n",
              "      <td>2176.284578</td>\n",
              "      <td>18.590902</td>\n",
              "      <td>25.349995</td>\n",
              "      <td>17.772827</td>\n",
              "      <td>19.884104</td>\n",
              "      <td>44.163109</td>\n",
              "      <td>68.365284</td>\n",
              "      <td>3566.653610</td>\n",
              "      <td>2061.533231</td>\n",
              "      <td>0.593558</td>\n",
              "      <td>1.830077</td>\n",
              "      <td>0.839921</td>\n",
              "      <td>1.533928</td>\n",
              "      <td>1.032268</td>\n",
              "      <td>1.885158</td>\n",
              "      <td>3558.225822</td>\n",
              "      <td>2057.441208</td>\n",
              "      <td>0.899122</td>\n",
              "      <td>2.312432</td>\n",
              "      <td>1.325438</td>\n",
              "      <td>2.295383</td>\n",
              "      <td>0.908968</td>\n",
              "      <td>...</td>\n",
              "      <td>2135.555927</td>\n",
              "      <td>18.112467</td>\n",
              "      <td>23.514646</td>\n",
              "      <td>9.089433</td>\n",
              "      <td>20.463689</td>\n",
              "      <td>40.165128</td>\n",
              "      <td>64.768686</td>\n",
              "      <td>3708.552141</td>\n",
              "      <td>2169.886880</td>\n",
              "      <td>19.450478</td>\n",
              "      <td>24.764949</td>\n",
              "      <td>15.423059</td>\n",
              "      <td>20.797828</td>\n",
              "      <td>42.884410</td>\n",
              "      <td>68.191273</td>\n",
              "      <td>3580.053926</td>\n",
              "      <td>2070.314385</td>\n",
              "      <td>1.129198</td>\n",
              "      <td>2.083349</td>\n",
              "      <td>1.628629</td>\n",
              "      <td>2.715756</td>\n",
              "      <td>3.462284</td>\n",
              "      <td>4.599409</td>\n",
              "      <td>3679.393107</td>\n",
              "      <td>2153.555265</td>\n",
              "      <td>19.979258</td>\n",
              "      <td>24.464488</td>\n",
              "      <td>13.488471</td>\n",
              "      <td>17.791111</td>\n",
              "      <td>40.754308</td>\n",
              "      <td>66.816547</td>\n",
              "      <td>3724.417296</td>\n",
              "      <td>2176.823208</td>\n",
              "      <td>18.159202</td>\n",
              "      <td>23.612639</td>\n",
              "      <td>14.378291</td>\n",
              "      <td>19.555084</td>\n",
              "      <td>43.210004</td>\n",
              "      <td>67.781924</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3567.710021</td>\n",
              "      <td>2062.112673</td>\n",
              "      <td>2.181775</td>\n",
              "      <td>3.610507</td>\n",
              "      <td>0.629608</td>\n",
              "      <td>2.155876</td>\n",
              "      <td>0.856275</td>\n",
              "      <td>2.233711</td>\n",
              "      <td>3562.787801</td>\n",
              "      <td>2059.317489</td>\n",
              "      <td>0.509250</td>\n",
              "      <td>1.478831</td>\n",
              "      <td>0.848642</td>\n",
              "      <td>2.539217</td>\n",
              "      <td>1.013335</td>\n",
              "      <td>1.562917</td>\n",
              "      <td>3727.061652</td>\n",
              "      <td>2181.935715</td>\n",
              "      <td>16.831394</td>\n",
              "      <td>32.474502</td>\n",
              "      <td>17.477847</td>\n",
              "      <td>23.278668</td>\n",
              "      <td>41.635879</td>\n",
              "      <td>65.650281</td>\n",
              "      <td>3566.313364</td>\n",
              "      <td>2061.497351</td>\n",
              "      <td>1.220105</td>\n",
              "      <td>1.708304</td>\n",
              "      <td>0.681477</td>\n",
              "      <td>1.139439</td>\n",
              "      <td>1.022393</td>\n",
              "      <td>1.847746</td>\n",
              "      <td>3557.952287</td>\n",
              "      <td>2057.698035</td>\n",
              "      <td>0.944458</td>\n",
              "      <td>2.068626</td>\n",
              "      <td>0.972430</td>\n",
              "      <td>1.510003</td>\n",
              "      <td>1.146271</td>\n",
              "      <td>...</td>\n",
              "      <td>2138.967337</td>\n",
              "      <td>19.870080</td>\n",
              "      <td>28.164362</td>\n",
              "      <td>13.937815</td>\n",
              "      <td>19.992277</td>\n",
              "      <td>37.654372</td>\n",
              "      <td>61.869855</td>\n",
              "      <td>3712.709484</td>\n",
              "      <td>2174.256181</td>\n",
              "      <td>19.891011</td>\n",
              "      <td>31.719748</td>\n",
              "      <td>15.828046</td>\n",
              "      <td>26.779568</td>\n",
              "      <td>40.708965</td>\n",
              "      <td>64.960239</td>\n",
              "      <td>3580.174518</td>\n",
              "      <td>2070.019706</td>\n",
              "      <td>0.933352</td>\n",
              "      <td>1.358187</td>\n",
              "      <td>1.487142</td>\n",
              "      <td>2.762906</td>\n",
              "      <td>2.735184</td>\n",
              "      <td>4.474138</td>\n",
              "      <td>3685.034466</td>\n",
              "      <td>2157.968999</td>\n",
              "      <td>19.918259</td>\n",
              "      <td>31.842462</td>\n",
              "      <td>12.808064</td>\n",
              "      <td>20.793709</td>\n",
              "      <td>38.074628</td>\n",
              "      <td>63.915386</td>\n",
              "      <td>3725.822160</td>\n",
              "      <td>2177.089059</td>\n",
              "      <td>19.737616</td>\n",
              "      <td>29.484396</td>\n",
              "      <td>15.793034</td>\n",
              "      <td>25.713513</td>\n",
              "      <td>39.250246</td>\n",
              "      <td>65.031031</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3565.546124</td>\n",
              "      <td>2063.128867</td>\n",
              "      <td>1.685161</td>\n",
              "      <td>3.384311</td>\n",
              "      <td>0.677526</td>\n",
              "      <td>1.795798</td>\n",
              "      <td>0.927924</td>\n",
              "      <td>1.909810</td>\n",
              "      <td>3562.655091</td>\n",
              "      <td>2059.139105</td>\n",
              "      <td>0.618655</td>\n",
              "      <td>1.891311</td>\n",
              "      <td>1.194787</td>\n",
              "      <td>2.279256</td>\n",
              "      <td>0.809706</td>\n",
              "      <td>1.570490</td>\n",
              "      <td>3730.834377</td>\n",
              "      <td>2178.202288</td>\n",
              "      <td>8.605323</td>\n",
              "      <td>29.230451</td>\n",
              "      <td>12.803166</td>\n",
              "      <td>35.672755</td>\n",
              "      <td>35.501254</td>\n",
              "      <td>68.565258</td>\n",
              "      <td>3566.892964</td>\n",
              "      <td>2061.410800</td>\n",
              "      <td>1.050362</td>\n",
              "      <td>1.648350</td>\n",
              "      <td>0.770318</td>\n",
              "      <td>0.866603</td>\n",
              "      <td>1.018056</td>\n",
              "      <td>1.833953</td>\n",
              "      <td>3557.210732</td>\n",
              "      <td>2057.551763</td>\n",
              "      <td>0.217481</td>\n",
              "      <td>2.111618</td>\n",
              "      <td>1.353791</td>\n",
              "      <td>1.861178</td>\n",
              "      <td>1.307935</td>\n",
              "      <td>...</td>\n",
              "      <td>2133.809957</td>\n",
              "      <td>5.340468</td>\n",
              "      <td>27.288250</td>\n",
              "      <td>10.857369</td>\n",
              "      <td>32.862238</td>\n",
              "      <td>33.195401</td>\n",
              "      <td>63.501683</td>\n",
              "      <td>3715.573148</td>\n",
              "      <td>2168.066755</td>\n",
              "      <td>7.283253</td>\n",
              "      <td>29.030922</td>\n",
              "      <td>16.642679</td>\n",
              "      <td>37.019613</td>\n",
              "      <td>35.319854</td>\n",
              "      <td>67.534290</td>\n",
              "      <td>3580.527194</td>\n",
              "      <td>2070.341557</td>\n",
              "      <td>1.163419</td>\n",
              "      <td>2.816887</td>\n",
              "      <td>0.983648</td>\n",
              "      <td>3.165612</td>\n",
              "      <td>2.492116</td>\n",
              "      <td>4.442776</td>\n",
              "      <td>3687.573738</td>\n",
              "      <td>2150.633349</td>\n",
              "      <td>5.319542</td>\n",
              "      <td>29.050032</td>\n",
              "      <td>9.947893</td>\n",
              "      <td>34.349046</td>\n",
              "      <td>35.357384</td>\n",
              "      <td>64.534645</td>\n",
              "      <td>3723.053978</td>\n",
              "      <td>2167.798335</td>\n",
              "      <td>8.429414</td>\n",
              "      <td>26.374975</td>\n",
              "      <td>14.920736</td>\n",
              "      <td>35.675266</td>\n",
              "      <td>33.901687</td>\n",
              "      <td>66.956313</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 114 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a187819d-729d-4ddc-a785-3a064b0beaae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a187819d-729d-4ddc-a785-3a064b0beaae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a187819d-729d-4ddc-a785-3a064b0beaae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Class  AF3 delta std  AF3 delta m  ...  AF4 beta std  AF4 beta m  user\n",
              "0    1.0    3569.164550  2063.892754  ...     46.280843   73.565719     0\n",
              "1    1.0    3568.423670  2063.099248  ...     38.559351   67.470041     0\n",
              "2    1.0    3568.157929  2062.445859  ...     43.210004   67.781924     0\n",
              "3    1.0    3567.710021  2062.112673  ...     39.250246   65.031031     0\n",
              "4    1.0    3565.546124  2063.128867  ...     33.901687   66.956313     0\n",
              "\n",
              "[5 rows x 114 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "collective_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpcDsLQ9aZHm"
      },
      "outputs": [],
      "source": [
        "collective_df[\"actual_class\"] = collective_df[\"Class\"].astype(str) + \"_\" + collective_df[\"user\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3BxZUYsbWHG"
      },
      "outputs": [],
      "source": [
        "collective_df.drop([\"Class\"],inplace=True,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1aSLyIebeyq"
      },
      "outputs": [],
      "source": [
        "genarlization_df =collective_df.loc[collective_df[\"user\"] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "monKMPUlboy4"
      },
      "outputs": [],
      "source": [
        "train_df = collective_df.loc[collective_df[\"user\"] != 1]\n",
        "#ds_train,ds_test,_,_ = train_test_split(train_df.values[:,1:],train_df.values[:,-1],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcRULKCzcZko",
        "outputId": "7bf68a96-ac93-43ed-a4a7-6e41b518c5e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ],
      "source": [
        "train_df.drop([\"user\"],axis=1,inplace=True)\n",
        "genarlization_df.drop([\"user\"],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xb6Dqlgc89B"
      },
      "outputs": [],
      "source": [
        "genarlization_arr = genarlization_df.values[:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp7M27U4dHVH"
      },
      "outputs": [],
      "source": [
        "ds_train,ds_test,_,_ = train_test_split(train_df.values[:,:],train_df.values[:,-1],test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXET--7MdU07",
        "outputId": "6c9aed80-347d-42a8-bc6c-89cbe77d5ff8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7776, 113)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "ds_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEYscvxNdSqZ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "meta_step_size = 0.10\n",
        "\n",
        "inner_batch_size = 25\n",
        "eval_batch_size = 25\n",
        "\n",
        "meta_iters = 3000\n",
        "eval_iters = 10\n",
        "inner_iters = 10\n",
        "\n",
        "eval_interval = 250\n",
        "train_shots = 30\n",
        "shots = 30\n",
        "classes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuBshUNJdTO0"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "  def __init__(self,training,gen_test=False):\n",
        "    if training:\n",
        "      ds = ds_train\n",
        "    else:\n",
        "      ds = ds_test\n",
        "\n",
        "    if gen_test:\n",
        "      ds = genarlization_arr\n",
        "\n",
        "    x = ds[:,:-1]\n",
        "    y = ds[:,-1]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    x = scaler.fit_transform(x)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "\n",
        "    self.data = {}\n",
        "\n",
        "    for img,label in dataset:\n",
        "      image = img.numpy()\n",
        "      lab = str(label.numpy().decode(\"utf-8\"))\n",
        "      if lab not in self.data:\n",
        "        self.data[lab] = []\n",
        "      self.data[lab].append(image)\n",
        "    self.labels = list(self.data.keys())\n",
        "\n",
        "  def get_mini_dataset(self, batch_size, repetitions, shots, num_classes, split=False):\n",
        "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
        "        temp_images = np.zeros(shape=(num_classes * shots, 112))\n",
        "        if split:\n",
        "            test_labels = np.zeros(shape=(num_classes))\n",
        "            test_images = np.zeros(shape=(num_classes, 112))\n",
        "\n",
        "        label_subset = random.choices(self.labels, k=num_classes)\n",
        "        for class_idx, class_obj in enumerate(label_subset):\n",
        "          \n",
        "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
        "            \n",
        "            if split:\n",
        "                test_labels[class_idx] = class_idx\n",
        "                images_to_split = random.choices(\n",
        "                    self.data[label_subset[class_idx]], k=shots + 1\n",
        "                )\n",
        "                test_images[class_idx] = images_to_split[-1]\n",
        "                temp_images[\n",
        "                    class_idx * shots : (class_idx + 1) * shots\n",
        "                ] = images_to_split[:-1]\n",
        "            else:\n",
        "               \n",
        "                temp_images[\n",
        "                    class_idx * shots : (class_idx + 1) * shots\n",
        "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(\n",
        "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
        "        )\n",
        "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
        "        if split:\n",
        "            return dataset, test_images, test_labels\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5Lq5BIoeJXQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(training=True)\n",
        "test_dataset = Dataset(training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E8e9JK4eO2T"
      },
      "outputs": [],
      "source": [
        "def ann_bn(x,n):\n",
        "    x = layers.Dense(n)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return layers.ReLU()(x)\n",
        "\n",
        "def dropout_layer(x,n):\n",
        "    return layers.Dropout(0.3)\n",
        "\n",
        "inputs = layers.Input(shape=(112,))\n",
        "x = ann_bn(inputs,512)\n",
        "x = ann_bn(x,768)\n",
        "x = ann_bn(x,1024)\n",
        "x = ann_bn(x,512)\n",
        "x = ann_bn(x,64)\n",
        "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile()\n",
        "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urihGtYtebzT",
        "outputId": "c4c0f880-b41f-4731-e7a7-a99eb5b94702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch 0: train=0.666667 test=1.000000\n",
            "batch 500: train=1.000000 test=1.000000\n",
            "batch 1000: train=0.333333 test=0.333333\n",
            "batch 1500: train=1.000000 test=0.333333\n",
            "batch 2000: train=1.000000 test=0.333333\n",
            "batch 2500: train=1.000000 test=0.333333\n"
          ]
        }
      ],
      "source": [
        "training = []\n",
        "testing = []\n",
        "for meta_iter in range(meta_iters):\n",
        "    frac_done = meta_iter / meta_iters\n",
        "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
        "    # Temporarily save the weights from the model.\n",
        "    old_vars = model.get_weights()\n",
        "    # Get a sample from the full dataset.\n",
        "    mini_dataset = train_dataset.get_mini_dataset(\n",
        "        inner_batch_size, inner_iters, train_shots, classes\n",
        "    )\n",
        "    for images, labels in mini_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = model(images)\n",
        "            loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    new_vars = model.get_weights()\n",
        "    # Perform SGD for the meta step.\n",
        "    for var in range(len(new_vars)):\n",
        "        new_vars[var] = old_vars[var] + (\n",
        "            (new_vars[var] - old_vars[var]) * cur_meta_step_size\n",
        "        )\n",
        "    # After the meta-learning step, reload the newly-trained weights into the model.\n",
        "    model.set_weights(new_vars)\n",
        "    # Evaluation loop\n",
        "    if meta_iter % eval_interval == 0:\n",
        "        accuracies = []\n",
        "        for dataset in (train_dataset, test_dataset):\n",
        "            # Sample a mini dataset from the full dataset.\n",
        "            train_set, test_images, test_labels = dataset.get_mini_dataset(\n",
        "                eval_batch_size, eval_iters, shots, classes, split=True\n",
        "            )\n",
        "            old_vars = model.get_weights()\n",
        "            # Train on the samples and get the resulting accuracies.\n",
        "            for images, labels in train_set:\n",
        "                with tf.GradientTape() as tape:\n",
        "                    preds = model(images)\n",
        "                    loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
        "                grads = tape.gradient(loss, model.trainable_weights)\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "            test_preds = model.predict(test_images)\n",
        "            test_preds = tf.argmax(test_preds).numpy()\n",
        "            num_correct = (test_preds == test_labels).sum()\n",
        "            # Reset the weights after getting the evaluation accuracies.\n",
        "            model.set_weights(old_vars)\n",
        "            accuracies.append(num_correct / classes)\n",
        "        training.append(accuracies[0])\n",
        "        testing.append(accuracies[1])\n",
        "        if meta_iter % 100 == 0:\n",
        "            print(\n",
        "                \"batch %d: train=%f test=%f\" % (meta_iter, accuracies[0], accuracies[1])\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wHs80Mlh23p"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def test_generalization(n):\n",
        "    gen_accuracy = []\n",
        "    gen_dataset = Dataset(training=False,gen_test=True) \n",
        "    for i in range (0,n):\n",
        "      train_set, test_images, test_labels = gen_dataset.get_mini_dataset(eval_batch_size, eval_iters, shots, classes, split=True)\n",
        "      for images, labels in train_set:\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = model(images)\n",
        "            loss = keras.losses.sparse_categorical_crossentropy(labels, preds)\n",
        "        grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "      test_preds = model.predict(test_images)\n",
        "      test_preds = tf.argmax(test_preds).numpy()\n",
        "      print(test_preds)\n",
        "      print(test_labels)\n",
        "      acc = accuracy_score(test_preds,test_labels)\n",
        "      print(acc)\n",
        "      gen_accuracy.append(acc)\n",
        "    return sum(gen_accuracy)/len(gen_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_accuracy = test_generalization(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fWs8fgTH_Hy",
        "outputId": "f4a579aa-3d3e-438b-befc-2ad3dcf9c3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 2]\n",
            "[0. 1. 2.]\n",
            "0.3333333333333333\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n",
            "[0 0 2]\n",
            "[0. 1. 2.]\n",
            "0.6666666666666666\n",
            "[0 1 0]\n",
            "[0. 1. 2.]\n",
            "0.6666666666666666\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n",
            "[0 2 0]\n",
            "[0. 1. 2.]\n",
            "0.3333333333333333\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n",
            "[0 1 2]\n",
            "[0. 1. 2.]\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4XcQF4xID3C",
        "outputId": "4b1de142-38de-4d9c-f1d0-f7347a5316c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ANN_META.ipynb",
      "provenance": [],
      "mount_file_id": "1JX7EmDHLeL6ZRn6UVakYxFqMUy_8uj6w",
      "authorship_tag": "ABX9TyMZvr8tKkIiEF0bFDO9/1ZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}